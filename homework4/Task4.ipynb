{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymorphy2\n",
    "analyzer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"galaxy_words.json\", encoding='utf-8') as f:\n",
    "    dict_w = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь с токенами и их частями речи и запишем его в файл json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_speech = {}\n",
    "for num in range(len(dict_w)):\n",
    "    lst = []\n",
    "    for word in dict_w[str(num)]['words']:\n",
    "        if analyzer.parse(word)[0].tag.POS is not None:\n",
    "            lst.append((word, analyzer.parse(word)[0].tag.POS))\n",
    "            words_speech[str(num)] = {'words_and_pos': lst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_with_pos.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(words_speech, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем средние доли для разных частей речи в разных документах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь с общим количеством каждой части речи для каждого документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = {}\n",
    "for i in list(words_speech.keys()):\n",
    "    list_of_w = words_speech[i]['words_and_pos']\n",
    "    list_of_speech = []\n",
    "    for j in range(len(list_of_w)):\n",
    "        if list_of_w[j][1] is not None:\n",
    "            list_of_speech.append(list_of_w[j][1])\n",
    "    speech[i] = dict(Counter(list_of_speech))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасет со средними долями каждой части речи в каждом документе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = []\n",
    "for i in list(speech.keys()):\n",
    "    for j in speech[str(i)].keys():\n",
    "        sp.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'PRTF', 'PRCL', 'NPRO', 'PRED', 'PRTS', 'ADJS', 'INTJ', 'PREP', 'GRND', 'NUMR', 'CONJ', 'ADVB', 'VERB', 'INFN', 'ADJF', 'COMP']\n"
     ]
    }
   ],
   "source": [
    "unique_speech = list(set(sp))\n",
    "print(unique_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'NOUN': [], 'PRTF': [], 'PRCL': [], 'NRPO': [],\n",
    "             'PRED': [], 'PRTS': [],'ADJS': [], 'INTJ': [],\n",
    "             'PREP': [], 'GRND': [], 'NUMR': [], 'CONJ': [], \n",
    "            'ADVB': [], 'VERB': [], 'INFN': [], 'ADJF': [], 'COMP': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = {}\n",
    "for i in list(speech.keys()):\n",
    "    count = 0\n",
    "    for j in list(speech[str(i)].keys()):\n",
    "        count += speech[str(i)][str(j)]\n",
    "    new_row = {}\n",
    "    for j in list(speech[str(i)].keys()):\n",
    "        mean = speech[str(i)][str(j)] / count\n",
    "        new_row.update({str(j): round(mean,2)})\n",
    "    data_df = data_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRTF</th>\n",
       "      <th>PRCL</th>\n",
       "      <th>NRPO</th>\n",
       "      <th>PRED</th>\n",
       "      <th>PRTS</th>\n",
       "      <th>ADJS</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>PREP</th>\n",
       "      <th>GRND</th>\n",
       "      <th>NUMR</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>ADVB</th>\n",
       "      <th>VERB</th>\n",
       "      <th>INFN</th>\n",
       "      <th>ADJF</th>\n",
       "      <th>COMP</th>\n",
       "      <th>NPRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NOUN  PRTF  PRCL  NRPO  PRED  PRTS  ADJS  INTJ  PREP  GRND  NUMR  CONJ  \\\n",
       "0  0.56  0.01  0.01   0.0   0.0  0.02  0.00   0.0  0.01  0.01   0.0  0.01   \n",
       "1  0.62  0.01  0.00   0.0   0.0  0.03  0.01   0.0  0.01  0.00   0.0  0.03   \n",
       "2  0.65  0.02  0.02   0.0   0.0  0.02  0.00   0.0  0.00  0.00   0.0  0.00   \n",
       "3  0.75  0.01  0.00   0.0   0.0  0.02  0.00   0.0  0.00  0.00   0.0  0.00   \n",
       "4  0.57  0.14  0.00   0.0   0.0  0.00  0.00   0.0  0.00  0.00   0.0  0.00   \n",
       "\n",
       "   ADVB  VERB  INFN  ADJF  COMP  NPRO  \n",
       "0  0.02  0.09   0.0  0.26   0.0  0.00  \n",
       "1  0.05  0.08   0.0  0.16   0.0  0.00  \n",
       "2  0.00  0.10   0.0  0.21   0.0  0.00  \n",
       "3  0.00  0.05   0.0  0.15   0.0  0.01  \n",
       "4  0.14  0.00   0.0  0.14   0.0  0.00  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем нетипичные документы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номера нетипичных документов для части речи NOUN: [106, 107, 116, 180, 188, 215, 239, 246, 253, 254, 255]\n",
      "Номера нетипичных документов для части речи PRTF: [4, 10, 32, 94, 173, 194, 197, 201, 228]\n",
      "Номера нетипичных документов для части речи PRCL: [85, 181, 182, 227, 228, 241]\n",
      "Номера нетипичных документов для части речи NRPO: []\n",
      "Номера нетипичных документов для части речи PRED: [21, 38, 87, 88, 100, 163, 214, 256]\n",
      "Номера нетипичных документов для части речи PRTS: [34, 35, 142, 181, 182, 215, 260]\n",
      "Номера нетипичных документов для части речи ADJS: [37, 66, 89, 125, 137, 149, 162, 201, 222]\n",
      "Номера нетипичных документов для части речи INTJ: [96, 169, 191]\n",
      "Номера нетипичных документов для части речи PREP: [13, 90, 182, 215, 226]\n",
      "Номера нетипичных документов для части речи GRND: [56, 68, 71, 103, 166, 193, 197, 207, 208, 220, 251, 252, 259]\n",
      "Номера нетипичных документов для части речи NUMR: [24, 75, 87, 89, 98, 126, 145, 179, 202, 253, 254]\n",
      "Номера нетипичных документов для части речи CONJ: [1, 17, 34, 64, 65, 135, 143, 152, 158, 160, 193, 207, 216, 253, 254]\n",
      "Номера нетипичных документов для части речи ADVB: [4, 32, 89, 119, 142, 150, 173]\n",
      "Номера нетипичных документов для части речи VERB: [108, 166, 209, 212, 213, 234]\n",
      "Номера нетипичных документов для части речи INFN: [13, 28, 49, 152, 153, 155, 160, 163, 173, 204]\n",
      "Номера нетипичных документов для части речи ADJF: [10, 12, 32, 35, 93, 109, 116, 125, 180, 181, 182, 201, 216, 239]\n",
      "Номера нетипичных документов для части речи COMP: [26, 40, 46, 48, 86, 98, 136, 141, 148, 154, 178, 190, 216, 222]\n",
      "Номера нетипичных документов для части речи NPRO: [7, 25, 35, 49, 90, 94, 125, 175, 216]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for name_of_sp in data_df.columns:\n",
    "    mean_noun = data_df[str(name_of_sp)].mean()\n",
    "    std_noun = np.std(data_df[str(name_of_sp)])\n",
    "    dif_more = mean_noun + 2 * std_noun\n",
    "    dif_less = mean_noun - 2 * std_noun\n",
    "    data = data_df[(data_df[str(name_of_sp)] > dif_more ) | (data_df[str(name_of_sp)] < dif_less)]\n",
    "    print('Номера нетипичных документов для части речи {}: {}'.format(str(name_of_sp), list(data.index)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
